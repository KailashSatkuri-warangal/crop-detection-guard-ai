# -*- coding: utf-8 -*-
"""Crop_detectionvalided.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IEDSv8P-kQ-rDtxz_XX4OAEIA07-kiJa
"""

import zipfile
import os
import shutil
import random
import numpy as np
import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping


zip_file = "dataset.zip"
extract_path = ""

with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Files extracted to:", extract_path)

train_dir = os.path.join(extract_path, 'dataset/train')
val_dir = os.path.join(extract_path, 'datasetvalidation')

os.makedirs(val_dir, exist_ok=True)
for category in ["healthy", "infected"]:
    os.makedirs(os.path.join(train_dir, category), exist_ok=True)
    os.makedirs(os.path.join(val_dir, category), exist_ok=True)

def split_data(source, destination, split_ratio=0.2):
    if not os.path.exists(source) or not os.listdir(source):
        raise ValueError(f"Source directory '{source}' does not exist or is empty.")

    images = [img for img in os.listdir(source) if img.lower().endswith((".jpg", ".png", ".jpeg"))]
    if not images:
        raise ValueError(f"No valid images found in {source}")

    random.shuffle(images)
    val_size = int(len(images) * split_ratio)
    val_images = images[:val_size]

    for img in val_images:
        shutil.move(os.path.join(source, img), os.path.join(destination, img))

for category in ["healthy", "infected"]:
    train_path = os.path.join(train_dir, category)
    val_path = os.path.join(val_dir, category)
    split_data(train_path, val_path)

# Print dataset sizes
print("Train directory:", {category: len(os.listdir(os.path.join(train_dir, category))) for category in ["healthy", "infected"]})
print("Validation directory:", {category: len(os.listdir(os.path.join(val_dir, category))) for category in ["healthy", "infected"]})

def train_model():
    train_datagen = ImageDataGenerator(
        rescale=1.0/255,
        rotation_range=20,
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.1,
        zoom_range=0.1,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    val_datagen = ImageDataGenerator(rescale=1.0/255)

    train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        shuffle=True
    )
    val_generator = val_datagen.flow_from_directory(
        val_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        shuffle=False  # Keep order for evaluation
    )

    if train_generator.samples == 0 or val_generator.samples == 0:
        raise ValueError("No images found in train or validation directories.")

    # Improved model with more capacity
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        MaxPooling2D(pool_size=(2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Conv2D(256, (3, 3), activation='relu'),  # Added layer
        MaxPooling2D(pool_size=(2, 2)),
        Flatten(),
        Dense(256, activation='relu'),  # Increased units
        Dropout(0.5),
        Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer=Adam(learning_rate=0.0001),  # Lower learning rate
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    model.summary()

    model_save_path = 'models/crop_infection_model.keras'
    os.makedirs('models', exist_ok=True)

    checkpoint = ModelCheckpoint(model_save_path, monitor='val_accuracy', save_best_only=True, mode='max')
    early_stopping = EarlyStopping(monitor='val_loss', patience=5)  # Increased patience

    history = model.fit(
        train_generator,
        epochs=20,  # Increased epochs
        validation_data=val_generator,
        callbacks=[checkpoint, early_stopping]
    )

    # Print training results
    print("Training history:", history.history)
    return model, history,val_generator

model, history,val_generator = train_model()

import matplotlib.pyplot as plt

def plot_training_history(history):
    plt.figure(figsize=(12, 5))

    # Plot Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Model Accuracy')

    # Plot Loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Model Loss')

    plt.show()

plot_training_history(history)

# def predict_leaf(image_path):
#     model = load_model('models/crop_infection_model.keras')
#     img = cv2.imread(image_path)

#     if img is None:
#         return 'Invalid Image or Not Found', 0

#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#     img = cv2.resize(img, (224, 224))
#     img_array = img / 255.0
#     img_array = np.expand_dims(img_array, axis=0)

#     prediction = model.predict(img_array)
#     pred_value = prediction[0][0]

#     gray_image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
#     blur_score = cv2.Laplacian(gray_image, cv2.CV_64F).var()
#     edge_count = np.count_nonzero(cv2.Canny(gray_image, 100, 200))

#     print(f"Blur Score: {blur_score}, Edge Count: {edge_count}, Prediction Value: {pred_value}")

#     if blur_score < 10:
#         return 'uncertain or undetectable', 100
#     if edge_count < 500:
#         return 'Not a leaf', 0
#     if pred_value >= 0.5:
#         confidence = (pred_value - 0.5) * 200 if pred_value > 0.5 else (0.5 - pred_value) * 200
#         return 'healthy', confidence
#     else:
#         confidence = (0.5 - pred_value) * 200 if pred_value < 0.5 else (pred_value - 0.5) * 200
#         return 'infected', confidence

# import os
# import cv2
# import matplotlib.pyplot as plt
# from tkinter import Tk, filedialog

# # Suppress tkinter main window
# Tk().withdraw()

# # Open file dialog
# uploaded_image_path = filedialog.askopenfilename(title="Select an image file")

# if uploaded_image_path and os.path.exists(uploaded_image_path):
#     result, confidence = predict_leaf(uploaded_image_path)
#     print(f"Prediction: {result} (Confidence: {confidence:.2f}%)")

#     # Display image with prediction
#     img = cv2.imread(uploaded_image_path)
#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#     plt.imshow(img)
#     plt.axis('off')
#     plt.text(10, 10, f"Prediction: {result}\nConfidence: {confidence:.2f}%",
#              fontsize=12, color='white', bbox=dict(facecolor='black', alpha=0.6))
#     plt.show()
# else:
#     print("No file selected or file not found.")

# import seaborn as sns
# def process_image(image_path):
#     img = cv2.imread(image_path)
#     if img is None:
#         print("Invalid Image or Not Found")
#         return
#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

#     sizes = [(250, 250, "250 x 250"), (224, 224, "224 x 224")]
#     fig, axes = plt.subplots(1, len(sizes), figsize=(10, 5), constrained_layout=True)
#     for ax, size in zip(axes, sizes):
#         resized = cv2.resize(img_rgb, size[:2])
#         ax.imshow(resized)
#         ax.set_title(size[2], fontsize=12, fontweight='bold')
#         ax.axis('off')
#     plt.show()

#     img_gray = cv2.cvtColor(cv2.resize(img_rgb, (224, 224)), cv2.COLOR_RGB2GRAY)
#     fig, ax = plt.subplots(figsize=(5, 5), constrained_layout=True)
#     ax.imshow(img_gray, cmap='gray')
#     ax.set_title("Grayscale (224 x 224)", fontsize=12, fontweight='bold')
#     ax.axis('off')
#     plt.show()

#     fig, ax = plt.subplots(figsize=(8, 5), constrained_layout=True)
#     for i, color in enumerate(('r', 'g', 'b')):
#         sns.lineplot(x=range(256), y=cv2.calcHist([img_rgb], [i], None, [256], [0, 256]).flatten(), color=color, label=f'{color.upper()} channel', ax=ax)
#     ax.set_title("RGB Color Histogram", fontsize=12, fontweight='bold')
#     ax.set_xlabel("Pixel Intensity", fontsize=10)
#     ax.set_ylabel("Frequency", fontsize=10)
#     ax.legend()
#     sns.despine()
#     plt.show()

# if uploaded:
#     uploaded_image_path = list(uploaded.keys())[0]
#     if os.path.exists(uploaded_image_path):
#         process_image(uploaded_image_path)
#     else:
#         print("File not found!")
# else:
#     print("No file uploaded.")

# import numpy as np
# from scipy import stats
# from tensorflow.keras.preprocessing.image import ImageDataGenerator

# import numpy as np
# from scipy import stats

# def evaluate_model(model, val_generator):
#     val_generator.reset()
#     preds = model.predict(val_generator)
#     pred_labels = (preds >= 0.5).astype(int).flatten()
#     true_labels = val_generator.classes

#     # T-test
#     healthy_preds = preds[true_labels == 0].flatten()
#     infected_preds = preds[true_labels == 1].flatten()
#     t_stat, p_value = stats.ttest_ind(healthy_preds, infected_preds, equal_var=False)
#     print(f"T-test statistic: {t_stat:.4f}, P-value (P-test): {p_value:.4f}")

#     # Z-test
#     correct = np.sum(pred_labels == true_labels)
#     total = len(true_labels)
#     p_hat = correct / total
#     p0 = 0.5
#     z_stat = (p_hat - p0) / np.sqrt(p0 * (1 - p0) / total)
#     p_value_z = 2 * (1 - stats.norm.cdf(abs(z_stat)))
#     print(f"Z-test statistic: {z_stat:.4f}, P-value: {p_value_z:.4f}")

#     # ANOVA test
#     f_stat, p_value_anova = stats.f_oneway(healthy_preds, infected_preds)
#     print(f"ANOVA F-statistic: {f_stat:.4f}, P-value: {p_value_anova:.4f}")

#     # Type I and Type II Errors
#     tn = np.sum((pred_labels == 0) & (true_labels == 0))
#     fp = np.sum((pred_labels == 1) & (true_labels == 0))
#     fn = np.sum((pred_labels == 0) & (true_labels == 1))
#     tp = np.sum((pred_labels == 1) & (true_labels == 1))

#     fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
#     fnr = fn / (fn + tp) if (fn + tp) > 0 else 0
#     print(f"Type I Error (False Positive Rate): {fpr:.4f}")
#     print(f"Type II Error (False Negative Rate): {fnr:.4f}")

# # Run evaluation
# evaluate_model(model, val_generator)

# import matplotlib.pyplot as plt

# def plot_training_history(history):
#     plt.figure(figsize=(12, 5))

#     # Plot Loss
#     plt.subplot(1, 2, 1)
#     plt.plot(history.history['loss'], label='Train Loss')
#     plt.plot(history.history['val_loss'], label='Validation Loss')
#     plt.xlabel('Epochs')
#     plt.ylabel('Loss')
#     plt.title('Training vs. Validation Loss')
#     plt.legend()

#     # Plot Accuracy
#     plt.subplot(1, 2, 2)
#     plt.plot(history.history['accuracy'], label='Train Accuracy')
#     plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
#     plt.xlabel('Epochs')
#     plt.ylabel('Accuracy')
#     plt.title('Training vs. Validation Accuracy')
#     plt.legend()

#     plt.show()

# # Run this after training the model
# plot_training_history(history)

# final_train_acc = history.history['accuracy'][-1]
# final_val_acc = history.history['val_accuracy'][-1]

# print(f"Final Training Accuracy: {final_train_acc:.4f}")
# print(f"Final Validation Accuracy: {final_val_acc:.4f}")

# import seaborn as sns
# from sklearn.metrics import confusion_matrix

# def plot_confusion_matrix(true_labels, pred_labels):
#     cm = confusion_matrix(true_labels, pred_labels)
#     plt.figure(figsize=(5, 4))
#     sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Healthy', 'Infected'], yticklabels=['Healthy', 'Infected'])
#     plt.xlabel('Predicted Label')
#     plt.ylabel('True Label')
#     plt.title('Confusion Matrix')
#     plt.show()

# # Run this after evaluation
# plot_confusion_matrix(val_generator.classes, (model.predict(val_generator) >= 0.5).astype(int).flatten())

# from sklearn.metrics import roc_curve

# def plot_roc_curve(model, val_generator):
#     preds = model.predict(val_generator).flatten()
#     true_labels = val_generator.classes

#     fpr, tpr, thresholds = roc_curve(true_labels, preds)
#     plt.figure(figsize=(6, 5))
#     plt.plot(fpr, tpr, label='ROC Curve', color='blue')
#     plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
#     plt.xlabel('False Positive Rate')
#     plt.ylabel('True Positive Rate')
#     plt.title('ROC Curve')
#     plt.legend()
#     plt.show()

#     best_threshold = thresholds[np.argmax(tpr - fpr)]
#     print(f"Best threshold: {best_threshold:.4f}")

# # Run this after evaluation
# plot_roc_curve(model, val_generator)

# model.save('/content/drive/MyDrive/daup/crop/crop_infection_model.keras')

# !ls /content/drive/MyDrive/daup/crop